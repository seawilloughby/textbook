{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Trees\n",
    "    1. Built with recursive binary splitting\n",
    "    1. Can't use RSS as criterion for split because categorical\n",
    "        1. classification error rate :\n",
    "            - more usefull for pruning. Also good for assessing accuracy\n",
    "        1. Gini index:\n",
    "            total variance across K classes\n",
    "            small gini means node has observations \n",
    "            mostly from a single class\n",
    "        1. Cross Entropy:\n",
    "\n",
    "    1. Advantages:\n",
    "        - easy to explain\n",
    "        - fits complicated nonlinear data\n",
    "        - easily handels qualitatve variables \n",
    "    1. Disadvantages:\n",
    "        - not as good predictive accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####example instantiations of algorithms  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import all the things from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clwilloughby/anaconda/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2507: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get a test dataset for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boston = load_boston() \n",
    "y = boston.target #house prices\n",
    "x = boston.data #13 features\n",
    "\n",
    "#put it into a test train set\n",
    "x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size = .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###examples of instantiating estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100,\n",
    "                           n_jobs=-1,\n",
    "                           random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingRegressor(learning_rate=0.1,\n",
    "                                 loss='ls',\n",
    "                                 n_estimators=100,\n",
    "                                 random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####max_depth:\n",
    "1. controls depth of interaction\n",
    "2. so, how many branches the tree goes. May be a stump of 1\n",
    "3. normally no more than 4, 6.\n",
    "\n",
    "#####min_samples_per_leaf\n",
    "1. don't want too few leaves (like only 1) , because then overfit to outliers\n",
    "\n",
    "#####n_estimators\n",
    "1. number of trees grown\n",
    "\n",
    "#####learning_rate\n",
    "1. slow is good. Lower rate needs more estimators \n",
    "2. really important parameter to tune!\n",
    "\n",
    "###Stochastic Gradient Boosting\n",
    "both of these can improve accuracy and reduce runtime\n",
    "#####max_features\n",
    "1. good when lots of features- randomly sample them\n",
    "\n",
    "####sub_sample\n",
    "1. random subset of training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abr = AdaBoostRegressor(DecisionTreeRegressor(),\n",
    "                        learning_rate=0.1,\n",
    "                        loss='linear',\n",
    "                        n_estimators=100,\n",
    "                        random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at every tree iteration,\n",
    "anything that was wrong (Residual) is given a weight for the next iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Run GradientBoosting in SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "#make a dictinoary of the parameters you want to alter in the gridsearch\n",
    "param_grid = {'learning rate': [0.1 0.05, 0.01] \n",
    "             'max depth': [4,6]\n",
    "             'min_samples_leaf': [3,4,5,9,17]\n",
    "             'max_features': [1.0, 0.3, 0.1]}\n",
    "\n",
    "'''instantiate your estimator. So, \n",
    "    AdaBoostRegressor\n",
    "    GradientBoostingRegressor\n",
    "    RandomForestRegressor'''\n",
    "#if changing learning rate, maybe make n estimators even higher...\n",
    "est = GradientBoostingRegressor(n_estimators = 3000)\n",
    "\n",
    "#run through ALL the parameters, and fit the data to all permutations\n",
    "gs_cv = GridSearchCV(est, param_grid).fit(x_train,y_train)\n",
    "#this will tell you what the best permaeters were\n",
    "gs_cv.best_params\n",
    "\n",
    "#if you want to call the chosen model, can also use this:\n",
    "best_rf_model = rf_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
